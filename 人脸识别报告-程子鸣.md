# 人脸识别报告

​姓名：程子鸣   



------

[TOC]

---

## 1 项目背景

### 1.1 人脸识别简述

​	人脸识别研究始于20世纪60年代，1990年之后，人脸识别逐渐步入初期阶段。随后深度学习应用于人脸识别当中，取得了令人惊叹的结果。直到今日，人脸识别技术还在不断发展。

​	人脸识别作为一个科研话题，实际上可以被分为两个部分：人脸检测和人脸识别。人脸检测负责检测映像媒体中属于人脸的部分；而人脸识别负责识别某一个特定的人。

​	人脸识别作为生物特征识别的应用之一，主要目的是设计一个人脸识别系统对不同人的人脸进行高效准确的识别。更优质的人脸识别系统能够在配合程度不高的情况下同样达到较好的效果。人脸识别系统主要包括四个组成部分，分别为：人脸图像采集及检测、人脸图像预处理、人脸图像特征提取以及匹配与识别。



### 1.2 人脸识别发展历史

​	在深度学习应用于人脸识别之前，人脸识别有许多不同的实现方法，不同的研究者围绕着这个话题提出了许多经典的算法。下图非常全面地展示了人脸识别发展的历史流程。

![image-20190214145934746](/Users/kha/Library/Application Support/typora-user-images/image-20190214145934746.png)





### 1.3 人脸图像数据库

​	FERET、CMU-PIE姿态光照表情人脸库、CAS-PEAL人脸库等等

​	本项目中主要使用以下两个人脸库

- Yale 人脸库
- ORL人脸库



## 2 项目内容

此人脸识别报告中包含了实际实习过程中或实现或详细了解的一些基本算法。

说明：项目中有些实验算法实现比较复杂，所以没有写入文档当中，此项目有关的所有代码均在 https://github.com/KHAKhazeus/try_face_recognition 上可以找到

### 2.1 基于肤色模型的人脸检测

#### 2.1.1 算法背景

​	人脸检测的经典算法中有许多致力于制定人工的规则或模式来提取人脸上某些特定的特征，来区分人脸区域与非人脸区域，由此诞生了许多不同但却十分有效的人脸检测算法，肤色模型便是其中的一种。肤色模型抓住了，人肤色这一特征，通过识别肤色从而框定人脸的大致范围。

​	许多研究者围绕肤色模型发表了一些文章，从理论上验证并完善了这一思路。一开始有人使用RGB颜色中的$$(r,g)$$分量来获得肤色模型中的基本阈值，随后便有人发文，认为人脸的肤色区域比较符合高斯分布，只需要确定均值和方差就能确定肤色模型的阈值。之后还有人利用了高斯混合模型来完善肤色模型，来使得肤色模型适用于不同种族和国家的人。



#### 2.1.2 算法原理

- 算法的关键在于根据前人的研究，能将肤色模型的肤色分布近似看做高斯分布，因此可以通过采样的方式，对肤色进行采集，通过采集来的肤色数据计算得出一个方差和均值，从而也就确定了算法索要使用的高斯肤色模型的所有参数。下图为高斯肤色模型的相关统计数学公式。

![image-20190214150804704](/Users/kha/Library/Application Support/typora-user-images/image-20190214150804704.png)

- 在判别某个色点是否是皮肤时，利用得到的高斯模型，反过来求该色点的概率密度，通过设定一定的阈值来判断是还是不是。
- 从步骤上来说如下流程图

``` mermaid
graph LR
A[采集人脸肤色数据] --> B[统计肤色数据]
B --> C[得到高斯肤色模型]
C --> D[使用肤色模型提取肤色]
D --> E[利用人脸的全局特征框定人脸]
```



#### 2.1.3  实际效果

- 图像数据预处理：

  ![image-20190214151513785](/Users/kha/Library/Application Support/typora-user-images/image-20190214151513785.png)

  ![image-20190214151650561](/Users/kha/Library/Application Support/typora-user-images/image-20190214151650561.png)



- 统计结果

  ![image-20190214151727050](/Users/kha/Library/Application Support/typora-user-images/image-20190214151727050.png)

- 实际检测效果

  ![image-20190214152017476](/Users/kha/Library/Application Support/typora-user-images/image-20190214152017476.png)



#### 2.1.4 实验代码

1. 图片预处理

```matlab
for i = 1:7
    filename = int2str(i);
    file = strcat(filename, '.jpeg');
    oriImage = imread(file);
    imageSegmenter(oriImage);
    reply = input('finished?', 's');
    maskpath = strcat(int2str(i),'.mat');
    save(maskpath, 'BW');
    imageSegmenter close
end
```

2. 统计高斯模型

```matlab
clear all;
clc;
cd white;
totalCr = 0;
totalCb = 0;
allValidPointsCR = [];
allValidPointsCB = [];
for i = 1:4
    maskname = strcat(int2str(i), '.mat');
    mask = load(maskname, '-mat');
    maskBW = mask.BW;
    ycbcrmaskOri = rgb2ycbcr(maskBW);
    ycbcrmask = ycbcrmaskOri;
    figure,imshow(ycbcrmask);
    ycrimageOri = ycbcrmask(:,:,3);
%     imshow(ycrimageOri);
    sizeMat = size(ycrimageOri);
    ycrimageOri = imresize(ycrimageOri, 1000/sizeMat(2));
    ycrimageOri = imresize(ycrimageOri, 1000/sizeMat(1));
    figure;imshow(ycrimageOri);
    sizeMat = size(ycrimageOri);
    ycrimage = reshape(ycrimageOri, [1,sizeMat(1)*sizeMat(2)]);
    ycrimage(find(ycrimage==128))=[];
%     imshow(ycrimage)
    allValidPointsCR = horzcat(allValidPointsCR, ycrimage);
    
    
    ycbimageOri = ycbcrmask(:,:,2);
%     imshow(ycbimageOri);
    sizeMat = size(ycbimageOri);
    ycbimage = reshape(ycbimageOri, [1,sizeMat(1)*sizeMat(2)]);
    ycbimage(find(ycbimage==128))=[];
%     imshow(ycbimage)
    allValidPointsCB = horzcat(allValidPointsCB, ycbimage);
end
allValidPointsCR = double(allValidPointsCR);
allValidPointsCB = double(allValidPointsCB);
sizeCR = size(allValidPointsCR,2);
sizeCB = size(allValidPointsCB,2);
if(sizeCR > sizeCB)
    len = sizeCB;
else
    len = sizeCR;
end
allValidPointsCR = allValidPointsCR(:,1:len);
allValidPointsCB = allValidPointsCB(:,1:len);
fprintf('Cb: E: %f,D :%f\nCr: E: %f, D: %f', ...
    mean(allValidPointsCB), std(allValidPointsCB), ...
    mean(allValidPointsCR), std(allValidPointsCR));
cov(allValidPointsCB, allValidPointsCR)
```

3. 测试

```matlab
clear all;  
clc;
M = [113.834270 149.178237]'  ;
Sigma = [34.8830   -7.4244
   -7.4244   81.4047];
testImg = imread('test4.jpeg');
figure,imshow(testImg),title('原始图像');
ycbcrTestImg = rgb2ycbcr(testImg);
oriImgSize = size(ycbcrTestImg);
if oriImgSize(2) > 1000 || oriImgSize(1) > 1000
    if(oriImgSize(2) > oriImgSize(1))
        rate = oriImgSize(2)/1000;
    else
        rate = oriImgSize(1)/1000;
    end
    testImg = imresize(testImg, 1/rate);
    ycbcrTestImg = rgb2ycbcr(testImg);
end
imgSize = size(ycbcrTestImg);
cbcr = zeros(2,1);
BinImg = zeros([imgSize(1), imgSize(2)]);
P = zeros([imgSize(1), imgSize(2)]);
for row = 1: imgSize(1)
    for col =1: imgSize(2)
        cbcr(2) = ycbcrTestImg(row,col,3); 
        cbcr(1) = ycbcrTestImg(row,col,2);
        P(row,col) = exp(-0.5*((cbcr-M)')*(inv(Sigma))*(cbcr-M));%计算似然度
        if P(row,col) > 0.15
             BinImg(row,col) = 1;%生成二值图像 
        end     
    end
end
figure,imshow(BinImg),title('二值化');

disk = strel('disk',2);
openBin=imopen(BinImg,disk);
% figure,imshow(BinImg),title('中间');
% [label, num] = bwlabel(BinImg, 8); % 区域标记
figure,imshow(openBin),title('中间');
[label, num] = bwlabel(openBin, 8); % 区域标记
stats = regionprops(label, 'BoundingBox'); % 得到包围矩形框
box = cat(1, stats.BoundingBox);
box = double(box);
[rowSize, olSize] = size(box);
sizeMat = box(:,3).*box(:,4);
mx = max(box(:,3).*box(:,4))/10;
figure,imshow(testImg),title('结果');
hold on;
for k = 1:rowSize
    p = box(k, 3)*box(k, 4);
    (double(box(k, 4))/double(box(k, 3)))
    if p>mx && 0.5 < (double(box(k, 4))/double(box(k, 3))) ...
        && (double(box(k, 4))/double(box(k, 3)))< 3
        rectangle('Position', box(k, :),'EdgeColor', 'r', 'LineWidth', 3);
    end
end
hold off;
```



#### 2.1.5 反思

- 对于此实验来说，建立肤色模型的数据是否全面充分是影响肤色模型质量和检测质量的一大因素，因而在实验我采用了Image Segmenter为每一张图片加上了一个mask，从而提取出了每一张图片中是肤色的部分进行统计。然而由于在YCbCr空间中肤色模型的方差相对于RGB来说较小，从而可能需要更多的图片来使肤色模型更加完善。
- 此实验中还有一个难点在于如何判断抽离的肤色点群哪些构成了人脸，在实验中我们先对点群进行了开运算，去除了一些游离的点，从而使判断能够更准确，随后通过长宽比和面积再加以判断，来框定人脸的位置。除此之外其实还有很多辅助判断的方法，例如抓住肤色识别中的空档部分，如眼镜，嘴巴，通过它们的大小、大致位置等进行人脸的判断。



### 2.2 基于EigenFace的人脸识别

#### 2.2.1 算法原理

​	EigenFace是由PCA算法中推导出来的人脸识别算法。EigenFace能够将人脸的信息降维，映射到不同的特征脸中去，通过特征脸的坐标来衡量不同图像中的脸的相似度，从而完成识别操作。

​	PCA是一个非常重要的降维算法，它致力于将样本各维去相关，其计算如下：

![image-20190214154713761](/Users/kha/Library/Application Support/typora-user-images/image-20190214154713761.png)

​	EigenFace便是从PCA中获得灵感，从而得到如下的识别系统：

![image-20190214154908136](/Users/kha/Library/Application Support/typora-user-images/image-20190214154908136.png)



#### 2.2.2 实际效果

1. 训练数据通过PCA算法，得到变换矩阵，从变换矩阵中得到特征脸

![image-20190214155341520](/Users/kha/Library/Application Support/typora-user-images/image-20190214155341520.png)

2. 用测试集进行测试

![image-20190214155510834](/Users/kha/Library/Application Support/typora-user-images/image-20190214155510834.png)



#### 2.2.3  实现代码

1. PCA

```matlab
clear;
clc;
% 1.读取图片，拉成等长向量，拼接为像素值*(15*8)的向量
% 2.行中心化
% 3.特征向量
% 4.W^T每一行是一个特征向量
% 5.W^T的特征值进行排列

for people = 1:15
    for faceNumber = 1:8
        if(people < 10)
            path = strcat('./Yale2/training/subject0', int2str(people), '_', ...
                int2str(faceNumber) , '.bmp');
        else
            path = strcat('./Yale2/training/subject', int2str(people), '_', ...
                int2str(faceNumber) , '.bmp');
        end
        face = imread(path);
        [row, col] = size(face);
        faceFlattened = reshape(face, [1,row * col]);
        bigX(:,(people-1) * 8 + faceNumber) = faceFlattened';
    end
end

bigX = double(bigX);

meanVector = mean(bigX, 2);
for i = 1: 15*8
    bigX(:, i) = bigX(:, i) - meanVector;
end

meanFace = reshape(meanVector, [100,100]);
figure,imshow(uint8(meanFace)),title('meanFace');

siCovX = bigX' * bigX;
[siFVec, siFMat] = eig(siCovX);
FVec = bigX * siFVec;
FVecRow = FVec';
totalVecRow = 0;
matSize = size(siFMat);
for i = matSize(1): -1 : 1
    if siFMat(i,i) < 1
        break;
    end
    totalVecRow = totalVecRow + 1;
    compressedFeatureVec(totalVecRow, :) = FVecRow(i, :);
end

compressedSize = size(compressedFeatureVec);
figure
for j = 1: 15
    featureVec = uint8(compressedFeatureVec(j, :));
    featureFace = reshape(featureVec, [100, 100]);
    subplot(4,4,j),imshow(featureFace);
end
save('compressedFeatureVec.mat', 'compressedFeatureVec');
save('bigX.mat', 'bigX');
save('meanVector.mat', 'meanVector');
save('meanFace.mat','meanFace');
```

2. 测试

```matlab
clear;
clc;

meanFacemat = load('meanFace.mat');
meanFace = meanFacemat.meanFace;
figure, imshow(uint8(meanFace)), title('meanFace');
compressedFeatureVecmat = load('compressedFeatureVec.mat');
compressedFeatureVec = compressedFeatureVecmat.compressedFeatureVec;
bigXmat = load('bigX.mat');
meanVector = load('meanVector.mat');
meanVector = meanVector.meanVector;
bigX = bigXmat.bigX;
[row, rep] = size(bigX);

figure,title('featureFace')
for i = 1:3
    for j = 1:3
        featureFaceVec = compressedFeatureVec((i - 1)*3 + j , :);
        featureFace = reshape(featureFaceVec, [100, 100]);
        subplot(3, 3, (i - 1)*3 + j);
        imshow(uint8(featureFace));
    end
end

% testImage = imread('./Yale2/training/subject15_5.bmp');
% testSize = size(testImage);
% testVec = reshape(testImage, [1, testSize(1) * testSize(2)]);
% testVec = double(testVec');
% testVec = testVec - meanVector;
% compressedX = compressedFeatureVec * bigX;
% compressedTest = compressedFeatureVec * testVec;
% minDistance = cos_distance(compressedX(:, 1), compressedTest);
% pos = 1;
% for j = 1: rep
%     newDistance = cos_distance(compressedX(:, j), compressedTest);
%     if newDistance < minDistance
%         minDistance = newDistance;
%         pos = j;
%     end
% end
% guess = floor((pos - 1) /8);
% fprintf("这人大概是对象%d", uint8(guess + 1));

total = 0;
correct = 0;

for i = 1: 15
    for j = 9: 11
        if i >=10
            path = strcat('./Yale2/test/subject', int2str(i),'_',...
                int2str(j), '.bmp');
        else
            path = strcat('./Yale2/test/subject0',int2str(i),'_',...
                int2str(j), '.bmp');
        end
        testImage = imread(path);
        testSize = size(testImage);
        testVec = reshape(testImage, [1, testSize(1) * testSize(2)]);
        testVec = double(testVec');
        testVec = testVec - meanVector;
        compressedX = compressedFeatureVec * bigX;
        compressedTest = compressedFeatureVec * testVec;
        minDistance = cos_distance(compressedX(:, 1), compressedTest);
        pos = 1;
        for k = 1: rep
            newDistance = cos_distance(compressedX(:, k), compressedTest);
            if newDistance < minDistance
                minDistance = newDistance;
                pos = k;
            end
        end
        guess = uint8(floor((pos - 1) /8) + 1);
%         fprintf("这人大概是对象%d", uint8(guess + 1));
        if(guess == i)
            correct = correct + 1;
        end
        total = total + 1;
    end
end

fprintf('准确率:%f', (correct/total) * 100);

function s = cos_distance(x, y)

all = vertcat(x', y');
s = pdist(all,'cosine');

end
```



#### 2.2.4 反思

- 本实验的重点在于PCA算法，EigenFace将PCA算法简单加工了一下，形成了一个效率比较高但十分简单的人脸识别算法。PCA算法在算协方差矩阵的特征向量这一步，如直接计算，对于图像这样大维度的数据，计算量非常庞大，计算速度很慢，在实验中，我将原数据构成的矩阵进行转置之后，再计算其协方差，得到的新协方差矩阵维度比原矩阵小很多，算出的特征向量最后左乘原矩阵即得到原协方差矩阵的特征向量，从而大幅减少了算法的计算时间。这个方法的原理如下
  $$
  AA^Tx_1 = \lambda_1 x_1 \\
  A^TAx_2 = \lambda_2 x_2 \quad AA^TAx_2 = A\lambda_2x_2 = \lambda_2Ax_2
  $$
  可见$$Ax_2$$是$$AA^T$$的特征向量。

  然而此方法仍然依赖于样本数量，当样本数量也很庞大的时候，这个方法也就不再适用。利用奇异值分解方法能够解决这个问题。



### 2.3  基于前馈神经网络的人脸识别

#### 2.3.1  实验原理

​	本实验是基于神经网络中最简单的全连接神经网络实现的人脸识别系统。本实验，我使用了两层400核的全连接层，最后再加上了一层40核的全连接层来对ORL数据库进行训练和测试。

​	神经网络模拟了人体中神经的工作方式，尝试通过这样的结构来让计算机来学习一些比较复杂的映射关系，从而完成智能识别等功能。

![image-20190214164240670](/Users/kha/Library/Application Support/typora-user-images/image-20190214164240670.png)

​	前馈神经网络只使用全连接层作为隐藏层，结构比较简单，但也能在人脸识别中达到比较好的识别效果。



#### 2.3.2  识别效果

- 测试效果

![image-20190214164726953](/Users/kha/Library/Application Support/typora-user-images/image-20190214164726953.png)

![image-20190214164818756](/Users/kha/Library/Application Support/typora-user-images/image-20190214164818756.png)



#### 2.3.3  反思

- 全连接的多层感知机在训练的过程中训练参数很多，所以相对比较难训练，在训练的过程中注意到，如果使用固定的学习率，神经网络在训练过程中损失值达到一定值会一直在该值附近浮动，不再有提升，因此在实现的过程中，我才有了指数递减的学习率来进行训练，最后效果不错。准确率达到了92.5百分点。



### 2.4  基于卷积神经网络的人脸识别

#### 2.4.1 实验原理

​	此实验为2.3实验基础上进行改进，将基于全连接的前馈神经网络改为带有卷积和池化层的卷积神经网络。

​	卷积神经网络特别设计了一些层，在减少参数的同时，还能保持很好的效果，通过这些特殊的层来增加网络的效率，但又不失去应有的复杂性，从而能够胜任更加复杂的任务。

​	卷积神经网络有三大特点：

- 局部连接

- 权重共享

- 空间或时间上的子采样

  本实验所用的卷积神经网络有多个，结构略有不同，但都用到了卷积层和池化层。



#### 2.4.2 实验效果

1. ORL数据集+tensorflow

   - 网络结构

   ![image-20190215100139710](/Users/kha/Library/Application Support/typora-user-images/image-20190215100139710.png)

   - 训练结果

   ![image-20190215095357916](/Users/kha/Library/Application Support/typora-user-images/image-20190215095357916.png)

   - t-SNE可视化

   ![image-20190215100334513](/Users/kha/Library/Application Support/typora-user-images/image-20190215100334513.png)

   - 测试结果

   ![image-20190215100347173](/Users/kha/Library/Application Support/typora-user-images/image-20190215100347173.png)

   

   2. Yale + Tensorflow

   - 训练结果

   ![image-20190215095701879](/Users/kha/Library/Application Support/typora-user-images/image-20190215095701879.png)



3. Yale + Tensorflow.keras

   - 网络结构

   ![image-20190215152252928](/Users/kha/Library/Application Support/typora-user-images/image-20190215152252928.png)

   ![image-20190215152322744](/Users/kha/Library/Application Support/typora-user-images/image-20190215152322744.png)

   - 训练结果

   ![image-20190215152345465](/Users/kha/Library/Application Support/typora-user-images/image-20190215152345465.png)



#### 2.4.3  实验代码

​	由于本实验代码较多，因此不再贴入本报告中，可在3.1中找到代码托管网站进行查看



#### 2.4.4 反思

​	实验的难点在于找到较优的卷积神经网络结构和图片数据的预处理，图片数据在读入之后要对其进行整理或变化之后使得数据便于参与训练，数据预处理很大程度影响了训练的效率和效果。卷积神经网络结构方面，在实验中我尝试了许多不同的神经网络结构，发现不同的神经网络之间效果差距可能很大，对于各种超参数的调整也会较大程度影响训练效果。



## 3 项目感想

### 3.1 总结

- 项目中尝试过的算法：

  - basic image processing algorithms

  - Face detection:

    - YCbCr Gaussian complexion model

  - Face recognition:

    - EigenFace

    - Multilayer perceptron
    - Naive CNN

  - Dimension reduction:

    - PCA

  - High dimension data visualization: 

    - tSNE

- 我所使用的工具：
  - matlab
  - jupyter notebook + tensorflow
- 代码托管网站： https://github.com/KHAKhazeus/try_face_recognition



### 3.2  体会

```
	这次的项目内容十分丰富，虽然只有短短的一周时间，但是在这段时间里我学到了许多新的知识，对于我来说更重要的是我在这次的项目中明白了从事科研的基本流程与要求。这对于想到国外读书的我颇有帮助。
	在这次项目中让我印象最深的是毛老师最后对我的一番点评。因为专业对口，所以在学校里我已经学习了许多软件开发的基本知识，在学校中也参加过实验室，虽然只是大二，但我已经明白科研对于我来说并不是一件容易的事情。在本科的学习过程，我对机器学习这方面比较感兴趣，我参加这个项目，是想通过这个项目来入手这个领域，想体验一下，从事这方面的科研工作会是什么样的感觉。在之前自学的过程当中，和毛老师指出的一样，我感觉到自己做出的作品其实缺少了自己的看法。自己知道借助某种方法能够解决一个问题，但很少尝试过实现自己的想法，更多的是借鉴。
	在这个项目中，在老师和助教的带领下，我跟随着自己的思路从零实现了一些简单的算法，这也是我学习生涯中比较少有的体验——从思路出发编程。我开始慢慢习惯了这样的过程。
	在解决某个问题的过程中，我也慢慢开始学会抓住自己的一些想法，并且尝试去实现它们，特别是一些现在的一些热门研究领域，工具还不充足的研究方向。
	在之后的学习过程中，我会更加深入地学习这一方面的知识，将在项目中只是简单了解的部分完善落实，并自己挖掘一些新的钻研点，例如：超参数的调整技巧，强化学习等。这次项目为我将来的学习打下了比较坚实的基础。
	感谢为这个项目付出的毛老师和助教，此次项目让我受益匪浅。
```

